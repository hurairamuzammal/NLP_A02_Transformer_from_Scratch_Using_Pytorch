{
  "model_architecture": {
    "src_vocab": 10000,
    "tgt_vocab": 10000,
    "N": 2,
    "d_model": 512,
    "d_ff": 2048,
    "h": 16,
    "dropout": 0.1
  },
  "training_info": {
    "t5_epochs": 15,
    "t5_best_val_loss": -0.7807021071721747,
    "causal_epochs": 50,
    "causal_best_val_loss": -0.33310420545532116,
    "tokenizer_vocab_size": 10000,
    "dataset_size": 20044,
    "train_size": 16035,
    "val_size": 2004,
    "test_size": 2005
  },
  "evaluation_metrics": {
    "t5_model": {
      "bleu": 0.0,
      "rougeL": 0.0,
      "token_accuracy": 0.3714646464646465,
      "word_overlap": 7.907590448766919,
      "char_similarity": 6.670877893259494,
      "length_ratio": 9.616607112384644
    },
    "causal_model": {
      "bleu": 0.0,
      "rougeL": 0.0,
      "token_accuracy": 53.702802415246886,
      "word_overlap": 56.14464497490813,
      "char_similarity": 37.32974018140622,
      "length_ratio": 39.47265178956777
    },
    "t5_perplexity": 2662.17705610054,
    "causal_perplexity": 1648.491675282496
  },
  "export_info": {
    "export_date": "2025-11-15T11:45:40.691249",
    "framework": "PyTorch",
    "python_version": "3.10+"
  }
}